{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sZXkuFM8nUvO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wl_j6cOeysoz"
   },
   "source": [
    "### Empirical Finance Tool\n",
    "#### Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6vX1WRH2Sss",
    "outputId": "568f7059-da3e-4f00-b095-4460b7c5a26c"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the data file including the .csv extension (already uploaded):  data.csv\n",
      "How many periods would you like to study? Please enter as an integer. 2\n",
      "Enter the start date (YYYYMM) for period 1:  196307\n",
      "Enter the end date (YYYYMM) for period 1:  199306\n",
      "Enter the start date (YYYYMM) for period 2:  199409\n",
      "Enter the end date (YYYYMM) for period 2:  202408\n"
     ]
    }
   ],
   "source": [
    "# Query the user for the file name, assuming file is already on the system\n",
    "file_path = input(\"Enter the name of the data file including the .csv extension (already uploaded): \")\n",
    "\n",
    "# Load the file and skipping rows without necessary information\n",
    "df = pd.read_csv(file_path, skiprows=1)\n",
    "\n",
    "# Rename the first column as 'Date'\n",
    "df.rename(columns={df.columns[0]: 'Date'}, inplace=True)\n",
    "\n",
    "# Drop unnamed rows\n",
    "df = df.drop(columns=df.filter(regex=\"Unnamed\").columns)\n",
    "\n",
    "# Query user for number of time frames\n",
    "nper = int(input('How many periods would you like to study? Please enter as an integer.'))\n",
    "\n",
    "# Query the user for a date range in YYYYMM format\n",
    "start_dates = []\n",
    "end_dates = []\n",
    "periods = []\n",
    "for i in range(nper):\n",
    "    start_date = input(f\"Enter the start date (YYYYMM) for period {i+1}: \")\n",
    "    start_dates.append(int(start_date))\n",
    "    start_year = start_date[2:4]\n",
    "    start_month = start_date[4:]\n",
    "    formatted_start_date = start_month + '/' + start_year\n",
    "    end_date = input(f\"Enter the end date (YYYYMM) for period {i+1}: \")\n",
    "    end_dates.append(int(end_date))\n",
    "    end_year = end_date[2:4]\n",
    "    end_month = end_date[4:]\n",
    "    formatted_end_date = end_month + '/' + end_year\n",
    "    formatted_period = formatted_start_date + ' - ' + formatted_end_date\n",
    "    periods.append(formatted_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwAEbcFu_PKN"
   },
   "source": [
    "## CAPM TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DGrjz3fC3TXM",
    "outputId": "cbac8ae6-dc04-4b79-edff-6af70b41b73f"
   },
   "outputs": [],
   "source": [
    "# Create a class to be used for all CAPM Calulcations\n",
    "class EmpiricalTestsCAPM:\n",
    "    def __init__(self, df):\n",
    "        # Drop the 'Date' column\n",
    "        self.df = df.drop(columns=['Date'], errors='ignore')\n",
    "\n",
    "        # Store portfolio columns, ignoring the factors and RF column\n",
    "        self.portfolio_columns = self.df.columns[:-4]\n",
    "        self.RMRF = self.df['RMRF']\n",
    "        self.SMB = self.df['SMB']\n",
    "        self.HML = self.df['HML']\n",
    "        self.RF = self.df['RF']\n",
    "        self.excess_returns = pd.DataFrame()\n",
    "        self.expected_returns = []\n",
    "\n",
    "\n",
    "    # Preliminary functions for getting returns (excess and expected)\n",
    "    def calculate_excess_returns(self):\n",
    "        # Calculate the excess returns\n",
    "        for column in self.portfolio_columns:\n",
    "            self.excess_returns[column] = self.df[column] - self.RF\n",
    "        print(\"Excess returns calculated.\")\n",
    "\n",
    "    def calculate_expected_returns(self):\n",
    "        # Calculate the expected returns\n",
    "        self.expected_returns = self.excess_returns.mean().values\n",
    "        print(\"Expected returns calculated.\")\n",
    "        return self.expected_returns\n",
    "\n",
    "    # Part 2c: Performing Time Series Regression\n",
    "    def calculate_TSR_CAPM(self):\n",
    "        # Ensure excess returns are calculated\n",
    "        if self.excess_returns.empty:\n",
    "            self.calculate_excess_returns()\n",
    "\n",
    "        # Create dictionaries to store metrics\n",
    "        self.capm_betas = {}\n",
    "        self.capm_betas_se = {}\n",
    "        self.capm_betas_tstat = {}\n",
    "        self.capm_alphas = {}\n",
    "        self.capm_alphas_se = {}\n",
    "        self.capm_alphas_tstat = {}\n",
    "\n",
    "        for column in self.portfolio_columns:\n",
    "            # Perform a time-series regression\n",
    "            X = sm.add_constant(self.RMRF)\n",
    "            y = self.excess_returns[column]\n",
    "            model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "            # Extract relevant metrics from the regression model\n",
    "            self.capm_betas[column] = model.params['RMRF']\n",
    "            self.capm_betas_se[column] = model.bse['RMRF']\n",
    "            self.capm_betas_tstat[column] = model.tvalues['RMRF']\n",
    "            self.capm_alphas[column] = model.params['const']\n",
    "            self.capm_alphas_se[column] = model.bse['const']\n",
    "            self.capm_alphas_tstat[column] = model.tvalues['const']\n",
    "\n",
    "        # Print results for confirmation\n",
    "        print(\"CAPM TSR metrics calculated.\")\n",
    "        return {\n",
    "            \"CAPM Betas\": self.capm_betas,\n",
    "            \"Beta_SE\": self.capm_betas_se,\n",
    "            \"Beta_tStat\": self.capm_betas_tstat,\n",
    "            \"Alphas\": self.capm_alphas,\n",
    "            \"Alpha_SE\":self.capm_alphas_se,\n",
    "            \"Alpha_tStat\": self.capm_alphas_tstat\n",
    "        }\n",
    "\n",
    "    # Part 2d: Perfoming Cross Sectional Regression\n",
    "    def calculate_CSR_CAPM(self):\n",
    "        # Conversions to ensure correct format\n",
    "        # Using the CAPM betas\n",
    "        capm_betas_series = pd.Series(self.capm_betas)\n",
    "        expected_returns_series = pd.Series(self.expected_returns, index=capm_betas_series.index)\n",
    "\n",
    "        # Perform a cross-sectional regression\n",
    "        X = sm.add_constant(capm_betas_series)\n",
    "        y = expected_returns_series\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        # Extract relevant metrics\n",
    "        lambda_value = model.params[0]\n",
    "        lambda_se = model.bse[0]\n",
    "        lambda_tstat = model.tvalues[0]\n",
    "\n",
    "        print(\"CAPM CSR metrics calculated.\")\n",
    "        return {\n",
    "            \"Lambda\": lambda_value,\n",
    "            \"Lambda_SE\": lambda_se,\n",
    "            \"Lambda_tStat\": lambda_tstat\n",
    "        }\n",
    "\n",
    "    # Part 2e: Performing Fama Macbeth Procedure\n",
    "    def calculate_FMP_CAPM(self):\n",
    "        # List to store lambdas at each time period t\n",
    "        lambdas_over_time = []\n",
    "\n",
    "        # Iterating over the time periods\n",
    "        for t in range(len(self.excess_returns)):\n",
    "            # Extract the excess return\n",
    "            excess_returns_t = self.excess_returns.iloc[t, :]\n",
    "\n",
    "            # Perform the cross-sectional regression for period t (using CAPM Betas)\n",
    "            X = sm.add_constant(pd.Series(self.capm_betas))\n",
    "            y = excess_returns_t\n",
    "            model = sm.OLS(y, X).fit()\n",
    "\n",
    "            # Extract metric\n",
    "            lambda_t = model.params[0]\n",
    "            lambdas_over_time.append(lambda_t)\n",
    "\n",
    "        # Return lambdas as a Series with time index and metrics\n",
    "        lambdas_series = pd.Series(lambdas_over_time, index=self.excess_returns.index, name=\"Lambda_t\")\n",
    "        lambda_hat = lambdas_series.mean()\n",
    "        lambda_se = lambdas_series.std() / np.sqrt(len(lambdas_series))\n",
    "        lambda_t_stat = lambda_hat / lambda_se\n",
    "\n",
    "\n",
    "        print(\"CAPM FMP results calculated.\")\n",
    "        return {\n",
    "            \"Lambda_hat\": lambda_hat,\n",
    "            \"Lambda_SE\": lambda_se,\n",
    "            \"Lambda_tStat\": lambda_t_stat\n",
    "        }\n",
    "\n",
    "    # Part 2f: Performing Time Series Joint Hypothesis Test (GRS)\n",
    "    def calculate_GRS_CAPM(self):\n",
    "      # Defining matrix to store residuals\n",
    "        residuals = pd.DataFrame(index=self.excess_returns.index, columns=self.excess_returns.columns)\n",
    "\n",
    "        # Calculate residuals for each portfolio and each time period\n",
    "        for portfolio in self.portfolio_columns:\n",
    "            # Extract the CAPM alpha and beta for this portfolio\n",
    "            alpha = self.capm_alphas[portfolio]\n",
    "            beta = self.capm_betas[portfolio]\n",
    "\n",
    "            # Calculate the predicted returns for each time period\n",
    "            predicted_returns = alpha + beta * self.df['RMRF']\n",
    "\n",
    "            # Compute residuals\n",
    "            residuals[portfolio] = self.excess_returns[portfolio] - predicted_returns\n",
    "\n",
    "        # Create a matrix of demeaned residuals\n",
    "        demeaned_residuals = residuals.subtract(residuals.mean(), axis=1)\n",
    "\n",
    "        # Define T, N, K\n",
    "        T = len(self.df)  # num periods\n",
    "        N = len(self.portfolio_columns)  # num portfolios\n",
    "        K = 1  # num factors\n",
    "\n",
    "        # Compute the covariance matrix\n",
    "        covariance_matrix = (demeaned_residuals.T @ demeaned_residuals) / (T - 1)\n",
    "        alpha_vector = np.array(list(self.capm_alphas.values()))\n",
    "        inv_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "\n",
    "        # Create a vector of expected returns of the facotrs (only 1 for CAPM)\n",
    "        mu_vec_factors = np.array([self.df['RMRF'].mean()])\n",
    "\n",
    "        # Compute the factor covariance matrix\n",
    "        cov_matrix_factors = np.array([[self.df['RMRF'].var(ddof=1)]])\n",
    "        inv_cov_matrix_factors = np.linalg.inv(cov_matrix_factors)\n",
    "\n",
    "        # Following the formula from the notes\n",
    "        # Calculate the denominator term\n",
    "        factor_term = mu_vec_factors.T @ inv_cov_matrix_factors @ mu_vec_factors\n",
    "        second_term_denom = 1 + factor_term\n",
    "\n",
    "        # Calculate the GRS F-statistic and Critical Value\n",
    "        first_term = (T - N - K) / N\n",
    "        second_term_num = alpha_vector.T @ inv_cov_matrix @ alpha_vector\n",
    "        f_grs = first_term * (second_term_num / second_term_denom)\n",
    "        f_critical = f.ppf(0.95, N, T - N - K)\n",
    "\n",
    "        print(\"CAPM GRS Test Completed.\")\n",
    "        return {\n",
    "            \"F_GRS\": f_grs,\n",
    "            \"F_Critical\": f_critical\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phe30hmQNjsm"
   },
   "source": [
    "## FAMA FRENCH 3-FACTOR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhFkvvIGNmtL",
    "outputId": "c9fa7e52-b479-485f-e29b-39dff9eb3e59"
   },
   "outputs": [],
   "source": [
    "# Create a class to be used for all FF3F Calulcations\n",
    "class EmpiricalTestsFF3F:\n",
    "    def __init__(self, df):\n",
    "        # Drop the 'Date' column\n",
    "        self.df = df.drop(columns=['Date'], errors='ignore')\n",
    "\n",
    "        # Store portfolio columns, ignoring the factors and RF column\n",
    "        self.portfolio_columns = self.df.columns[:-4]\n",
    "        self.RMRF = self.df['RMRF']\n",
    "        self.SMB = self.df['SMB']\n",
    "        self.HML = self.df['HML']\n",
    "        self.RF = self.df['RF']\n",
    "        self.excess_returns = pd.DataFrame()\n",
    "        self.expected_returns = []\n",
    "\n",
    "    # Preliminary functions for getting returns (excess and expected)\n",
    "    def calculate_excess_returns(self):\n",
    "        # Calculate the excess returns\n",
    "        for column in self.portfolio_columns:\n",
    "            self.excess_returns[column] = self.df[column] - self.RF\n",
    "        print(\"Excess returns calculated.\")\n",
    "        return self.excess_returns\n",
    "\n",
    "    def calculate_expected_returns(self):\n",
    "        # Calculate the expected returns\n",
    "        self.expected_returns = self.excess_returns.mean().values\n",
    "        print(\"Expected returns calculated.\")\n",
    "        return self.expected_returns\n",
    "\n",
    "    # Part 3b: Performing Time Series Regression\n",
    "    def calculate_TSR_FF3F(self):\n",
    "        # Ensure excess returns are calculated\n",
    "        if self.excess_returns.empty:\n",
    "            self.calculate_excess_returns()\n",
    "\n",
    "        # Create dictionaries to store metrics\n",
    "        self.ff3f_betas = {}\n",
    "        self.ff3f_betas_se = {}\n",
    "        self.ff3f_betas_tstat = {}\n",
    "        self.ff3f_alphas = {}\n",
    "        self.ff3f_alphas_se = {}\n",
    "        self.ff3f_alphas_tstat = {}\n",
    "\n",
    "        for column in self.portfolio_columns:\n",
    "            # Performing multi-variate regression using all three factors\n",
    "            X = sm.add_constant(self.df[['RMRF', 'SMB', 'HML']])\n",
    "            y = self.excess_returns[column]\n",
    "            model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "            # Store all metrics\n",
    "            self.ff3f_betas[column] = model.params[['RMRF', 'SMB', 'HML']]\n",
    "            self.ff3f_betas_se[column] = model.bse[['RMRF', 'SMB', 'HML']]\n",
    "            self.ff3f_betas_tstat[column] = model.tvalues[['RMRF', 'SMB', 'HML']]\n",
    "            self.ff3f_alphas[column] = model.params['const']\n",
    "            self.ff3f_alphas_se[column] = model.bse['const']\n",
    "            self.ff3f_alphas_tstat[column] = model.tvalues['const']\n",
    "\n",
    "        # Print results for confirmation\n",
    "        print(\"FF3F TSR metrics calculated.\")\n",
    "        return {\n",
    "            \"FF3F Betas\": self.ff3f_betas,\n",
    "            \"Beta_SE\": self.ff3f_betas_se,\n",
    "            \"Beta_tStat\": self.ff3f_betas_tstat,\n",
    "            \"Alphas\": self.ff3f_alphas,\n",
    "            \"Alpha Standard Errors\": self.ff3f_alphas_se,\n",
    "            \"Alpha t-Statistics\": self.ff3f_alphas_tstat\n",
    "        }\n",
    "\n",
    "    # Part 3c: Performing Cross Sectional Regression\n",
    "    def calculate_CSR_FF3F(self):\n",
    "        # Conversions to align format\n",
    "        # Extracting matrix of betas of all three facotrs\n",
    "        ff3f_betas_df = pd.DataFrame(self.ff3f_betas).T\n",
    "        expected_returns_series = pd.Series(self.expected_returns, index=ff3f_betas_df.index)\n",
    "\n",
    "        # Performing regression\n",
    "        X = sm.add_constant(ff3f_betas_df)\n",
    "        y = expected_returns_series\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        # Extract metrics for each factor\n",
    "        lambdas = model.params[1:]\n",
    "        lambda_se = model.bse[1:]\n",
    "        lambda_tstat = model.tvalues[1:]\n",
    "\n",
    "        print(\"FF3F CSR metrics calculated.\")\n",
    "        return {\n",
    "            \"Lambdas\": lambdas,\n",
    "            \"Lambda_SE\": lambda_se,\n",
    "            \"Lambda_tStat\": lambda_tstat\n",
    "        }\n",
    "\n",
    "    # Part 3d: Performing Fama Macbeth Procedure\n",
    "    def calculate_FMP_FF3F(self):\n",
    "        # List to store lambdas at each time period t\n",
    "        lambdas_over_time = []\n",
    "\n",
    "        # Iterating over the time periods\n",
    "        for t in range(len(self.excess_returns)):\n",
    "            # Extract excess returns\n",
    "            excess_returns_t = self.excess_returns.iloc[t, :]\n",
    "\n",
    "            # Perform the regression for using all factor betas\n",
    "            X = sm.add_constant(pd.DataFrame(self.ff3f_betas).T)\n",
    "            y = excess_returns_t\n",
    "            model = sm.OLS(y, X).fit()\n",
    "\n",
    "            # Extract lambdas for all factors\n",
    "            lambda_t = model.params[1:]\n",
    "            lambdas_over_time.append(lambda_t)\n",
    "\n",
    "        # Convert to df for further metric calculations\n",
    "        lambdas_df = pd.DataFrame(lambdas_over_time, index=self.excess_returns.index)\n",
    "        lambda_hat = lambdas_df.mean()\n",
    "        lambda_se = lambdas_df.std() / np.sqrt(len(lambdas_df))\n",
    "        lambda_t_stat = lambda_hat / lambda_se\n",
    "\n",
    "\n",
    "        print(\"FF3F FMP results calculated.\")\n",
    "        return {\n",
    "            \"Lambdas\": lambda_hat,\n",
    "            \"Lambda_SE\": lambda_se,\n",
    "            \"Lambda_tStat\": lambda_t_stat\n",
    "        }\n",
    "\n",
    "    # Part 3e: Performing Time Series Joint Hypothesis Test (GRS)\n",
    "    def calculate_GRS_FF3F(self):\n",
    "        # Create a matrix to store residuals\n",
    "        residuals = pd.DataFrame(index=self.excess_returns.index, columns=self.excess_returns.columns)\n",
    "\n",
    "        # Calculate residuals for each portfolio and each time period\n",
    "        for portfolio in self.portfolio_columns:\n",
    "            # Retrieve the FF3F alpha and betas for this portfolio\n",
    "            alpha = self.ff3f_alphas[portfolio]\n",
    "            betas = self.ff3f_betas[portfolio]\n",
    "\n",
    "            # Calculate the predicted returns for each time period\n",
    "            predicted_returns = alpha + (betas['RMRF'] * self.df['RMRF'] +\n",
    "                                         betas['SMB'] * self.df['SMB'] +\n",
    "                                         betas['HML'] * self.df['HML'])\n",
    "\n",
    "            # Compute residuals\n",
    "            residuals[portfolio] = self.excess_returns[portfolio] - predicted_returns\n",
    "\n",
    "        demeaned_residuals = residuals.subtract(residuals.mean(), axis=1)\n",
    "\n",
    "        # Define T, N, K\n",
    "        T = len(self.df)  # num periods\n",
    "        N = len(self.portfolio_columns)  # num portfolios\n",
    "        K = 3  # num factors\n",
    "\n",
    "        # Create the covariance matrix\n",
    "        covariance_matrix = (demeaned_residuals.T @ demeaned_residuals) / (T - 1)\n",
    "        alpha_vector = np.array(list(self.ff3f_alphas.values()))\n",
    "        inv_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "\n",
    "        # Create a vector of expected returns of the facotrs\n",
    "        mu_vec_factors = np.array([self.df['RMRF'].mean(), self.df['SMB'].mean(), self.df['HML'].mean()])\n",
    "\n",
    "        # Create the factor covariance matrix\n",
    "        cov_matrix_factors = self.df[['RMRF', 'SMB', 'HML']].cov()\n",
    "        inv_cov_matrix_factors = np.linalg.inv(cov_matrix_factors)\n",
    "\n",
    "        # Calculate the denominator term with the factor mean vector and factor covariance matrix\n",
    "        factor_term = mu_vec_factors.T @ inv_cov_matrix_factors @ mu_vec_factors\n",
    "        second_term_denom = 1 + factor_term\n",
    "\n",
    "        # Following the formula, calculate the GRS F-statistic and Critical Value\n",
    "        first_term = (T - N - K) / N\n",
    "        second_term_num = alpha_vector.T @ inv_cov_matrix @ alpha_vector\n",
    "        f_grs = first_term * (second_term_num / second_term_denom)\n",
    "        f_critical = f.ppf(0.95, N, T - N - K)\n",
    "\n",
    "        print(\"FF3F GRS Test completed.\")\n",
    "        return {\n",
    "            \"F_GRS\": f_grs,\n",
    "            \"F_Critical\": f_critical\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSyi6xgCcm9v"
   },
   "source": [
    "## Writing Output To Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works besides tests for CAPM (tried fixing)\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Font, Alignment, PatternFill\n",
    "import pandas as pd\n",
    "\n",
    "def write_CAPM_to_excel(wb, capm_csr_results, fmp_results, grs_results, filename=\"CAPM_Test.xlsx\"):\n",
    "    # Initialize the active sheet in the workbook\n",
    "    ws = wb.active\n",
    "    ws.title = \"CAPM Test Results\"\n",
    "\n",
    "    # Define styles for headers and cells\n",
    "    header_font = Font(bold=True, size=14)\n",
    "    header_fill = PatternFill(start_color=\"D9D9D9\", end_color=\"D9D9D9\", fill_type=\"solid\")\n",
    "    alignment_center = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "    # CAPM Test Header\n",
    "    ws[\"A1\"] = \"CAPM TEST\"\n",
    "    ws[\"A1\"].font = header_font\n",
    "\n",
    "    # Helper function to style headers\n",
    "    def style_header(row, headers):\n",
    "        for col, header in enumerate(headers, start=1):\n",
    "            cell = ws.cell(row=row, column=col, value=header)\n",
    "            cell.font = Font(bold=True)\n",
    "            cell.fill = header_fill\n",
    "            cell.alignment = alignment_center\n",
    "\n",
    "    # Function to write DataFrame data to specific location\n",
    "    def write_df_to_sheet(df, start_row):\n",
    "        for i, (index, row) in enumerate(df.iterrows(), start=start_row):\n",
    "            ws[f\"A{i}\"] = index  # Write the index as \"Time Period\"\n",
    "            for j, value in enumerate(row, start=2):\n",
    "                ws.cell(row=i, column=j, value=value)\n",
    "\n",
    "    # 1. Cross-Sectional Regression Section\n",
    "    ws[\"A3\"] = \"Cross Sectional Regression: E(Rᵉᵢₜ) = (γ) + βᵢλₜ + αᵢ, i = 1 ... N, ∀t\"\n",
    "    ws[\"A3\"].font = Font(bold=True)\n",
    "\n",
    "    # Headers for Cross-Sectional Regression Table\n",
    "    style_header(4, [\"Time Period\", \"Lambda (β)\", \"Standard Error\", \"T-Statistic\", \"Significant?\"])\n",
    "    write_df_to_sheet(capm_csr_results, start_row=5)\n",
    "\n",
    "    # 2. FMP Regression Section (Place directly after CSR table)\n",
    "    start_row_fmp = 5 + len(capm_csr_results) + 1\n",
    "    ws[f\"A{start_row_fmp}\"] = \"FMP Regression: Rᵉᵢₜ = βᵢλₜ + αᵢ, i = 1 ... N, ∀t\"\n",
    "    ws[f\"A{start_row_fmp}\"].font = Font(bold=True)\n",
    "\n",
    "    # Headers for FMP Regression Table\n",
    "    style_header(start_row_fmp + 1, [\"Time Period\", \"Lambda (β)\", \"Standard Error\", \"T-Statistic\", \"Significant?\"])\n",
    "    write_df_to_sheet(fmp_results, start_row=start_row_fmp + 2)\n",
    "\n",
    "    # 3. GRS F-Test Section (Place directly after FMP table)\n",
    "    start_row_grs = start_row_fmp + len(fmp_results) + 3\n",
    "    ws[f\"A{start_row_grs}\"] = \"GRS F-Test: f₍GRS₎ = ((T - N - K) / N) * ((α' Σₑ⁻¹ α) / (1 + μ' Σᵣ⁻¹ μ)) ∼ F(N, T - N - K)\"\n",
    "    ws[f\"A{start_row_grs}\"].font = Font(bold=True)\n",
    "\n",
    "    # Headers for GRS F-Test Table\n",
    "    style_header(start_row_grs + 1, [\"Time Period\", \"f₍GRS₎\", \"Critical Value\", \"Reject/Fail to Reject Null?\"])\n",
    "    \n",
    "    # Write GRS results with reject/fail to reject logic\n",
    "    for i, period in enumerate(grs_results.index, start=start_row_grs + 2):\n",
    "        ws[f\"A{i}\"] = period\n",
    "        ws[f\"B{i}\"] = grs_results.loc[period, \"F_GRS\"]\n",
    "        ws[f\"C{i}\"] = grs_results.loc[period, \"F_Critical\"]\n",
    "        ws[f\"D{i}\"] = \"Reject\" if grs_results.loc[period, \"F_GRS\"] >= grs_results.loc[period, \"F_Critical\"] else \"Fail to Reject\"\n",
    "\n",
    "    # Save the workbook\n",
    "    wb.save(filename)\n",
    "    print(f\"Results successfully saved to {filename}\")\n",
    "\n",
    "def write_FF3F_to_excel(wb, ff3f_csr_results, ff3f_fmp_results, ff3f_grs_results):\n",
    "    # Create a new sheet for FF3F results\n",
    "    ws = wb.create_sheet(title=\"FF3F Test Results\")\n",
    "\n",
    "    # Define styles for headers and cells\n",
    "    header_font = Font(bold=True)\n",
    "    header_fill = PatternFill(start_color=\"D9D9D9\", end_color=\"D9D9D9\", fill_type=\"solid\")\n",
    "    alignment_center = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "\n",
    "    # FF3F Test Header\n",
    "    ws.merge_cells(\"A1:J1\")\n",
    "    ws[\"A1\"] = \"FF3F TEST\"\n",
    "    ws[\"A1\"].font = Font(bold=True, size=14)\n",
    "\n",
    "    # Cross-Sectional Regression Section\n",
    "    ws.merge_cells(\"A3:J3\")\n",
    "    ws[\"A3\"] = \"Cross Sectional Regression: E(Rᵉᵢₜ) = (γ) + βᵢλₜ + αᵢ, i = 1 ... N, ∀t\"\n",
    "    ws[\"A3\"].font = Font(bold=True)\n",
    "\n",
    "    # Define factor names based on columns in the results DataFrame\n",
    "    factors = ff3f_csr_results[\"Lambdas\"].columns\n",
    "\n",
    "    # Headers for Cross-Sectional Regression Table\n",
    "    headers = [\"Time Period\"]\n",
    "    for factor in factors:\n",
    "        headers.extend([f\"λ_{factor}\", f\"σ(λ_{factor})\", f\"t(λ_{factor})\"])\n",
    "\n",
    "    # Write headers to Excel\n",
    "    for col, header in enumerate(headers, start=1):\n",
    "        ws.cell(row=4, column=col).value = header\n",
    "        ws.cell(row=4, column=col).font = header_font\n",
    "        ws.cell(row=4, column=col).fill = header_fill\n",
    "        ws.cell(row=4, column=col).alignment = alignment_center\n",
    "\n",
    "    # Fill Cross-Sectional Regression Table Data\n",
    "    for i, (period, row) in enumerate(ff3f_csr_results[\"Lambdas\"].iterrows(), start=5):\n",
    "        ws[f\"A{i}\"] = period\n",
    "        col_index = 2\n",
    "        for factor in factors:\n",
    "            ws.cell(row=i, column=col_index).value = row[factor]\n",
    "            ws.cell(row=i, column=col_index + 1).value = ff3f_csr_results[\"Lambda_SE\"].loc[period, factor]\n",
    "            ws.cell(row=i, column=col_index + 2).value = ff3f_csr_results[\"Lambda_tStat\"].loc[period, factor]\n",
    "            col_index += 3\n",
    "\n",
    "    # FMP Regression Section\n",
    "    start_row_fmp = i + 2  # Place FMP table after CSR table\n",
    "    ws.merge_cells(f\"A{start_row_fmp}:J{start_row_fmp}\")\n",
    "    ws[f\"A{start_row_fmp}\"] = \"FMP Regression: Rᵉᵢₜ = βᵢλₜ + αᵢ, i = 1 ... N, ∀t\"\n",
    "    ws[f\"A{start_row_fmp}\"].font = Font(bold=True)\n",
    "\n",
    "    # Write FMP Regression Table Headers\n",
    "    for col, header in enumerate(headers, start=1):\n",
    "        ws.cell(row=start_row_fmp + 1, column=col).value = header\n",
    "        ws.cell(row=start_row_fmp + 1, column=col).font = header_font\n",
    "        ws.cell(row=start_row_fmp + 1, column=col).fill = header_fill\n",
    "        ws.cell(row=start_row_fmp + 1, column=col).alignment = alignment_center\n",
    "\n",
    "    # Fill FMP Regression Table Data\n",
    "    for i, (period, row) in enumerate(ff3f_fmp_results[\"Lambdas\"].iterrows(), start=start_row_fmp + 2):\n",
    "        ws[f\"A{i}\"] = period\n",
    "        col_index = 2\n",
    "        for factor in factors:\n",
    "            ws.cell(row=i, column=col_index).value = row[factor]\n",
    "            ws.cell(row=i, column=col_index + 1).value = ff3f_fmp_results[\"Lambda_SE\"].loc[period, factor]\n",
    "            ws.cell(row=i, column=col_index + 2).value = ff3f_fmp_results[\"Lambda_tStat\"].loc[period, factor]\n",
    "            col_index += 3\n",
    "\n",
    "    # GRS F-Test Section\n",
    "    start_row_grs = i + 2  # Place GRS table after FMP table\n",
    "    ws.merge_cells(f\"A{start_row_grs}:D{start_row_grs}\")\n",
    "    ws[f\"A{start_row_grs}\"] = \"GRS F-Test: f₍GRS₎ = ((T - N - K) / N) * ((α' Σₑ⁻¹ α) / (1 + μ' Σᵣ⁻¹ μ)) ∼ F(N, T - N - K)\"\n",
    "    ws[f\"A{start_row_grs}\"].font = Font(bold=True)\n",
    "\n",
    "    # Headers for GRS F-Test Table\n",
    "    grs_headers = [\"Time Period\", \"f₍GRS₎\", \"Critical Value\", \"Reject/Fail to Reject Null?\"]\n",
    "    for col, header in enumerate(grs_headers, start=1):\n",
    "        ws.cell(row=start_row_grs + 1, column=col).value = header\n",
    "        ws.cell(row=start_row_grs + 1, column=col).font = header_font\n",
    "        ws.cell(row=start_row_grs + 1, column=col).fill = header_fill\n",
    "        ws.cell(row=start_row_grs + 1, column=col).alignment = alignment_center\n",
    "\n",
    "    # Fill GRS F-Test Table Data\n",
    "    for i, period in enumerate(ff3f_grs_results.index, start=start_row_grs + 2):\n",
    "        ws[f\"A{i}\"] = period\n",
    "        ws[f\"B{i}\"] = ff3f_grs_results.loc[period, \"F_GRS\"]\n",
    "        ws[f\"C{i}\"] = ff3f_grs_results.loc[period, \"F_Critical\"]\n",
    "        ws[f\"D{i}\"] = \"Reject\" if ff3f_grs_results.loc[period, \"F_GRS\"] > ff3f_grs_results.loc[period, \"F_Critical\"] else \"Fail to Reject\"\n",
    "\n",
    "    print(\"FF3F results successfully written to Excel sheet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting results for time period 1\n",
      "Excess returns calculated.\n",
      "Expected returns calculated.\n",
      "CAPM TSR metrics calculated.\n",
      "CAPM CSR metrics calculated.\n",
      "CAPM FMP results calculated.\n",
      "CAPM GRS Test Completed.\n",
      "Excess returns calculated.\n",
      "Expected returns calculated.\n",
      "FF3F TSR metrics calculated.\n",
      "FF3F CSR metrics calculated.\n",
      "FF3F FMP results calculated.\n",
      "FF3F GRS Test completed.\n",
      "\n",
      "\n",
      "Getting results for time period 2\n",
      "Excess returns calculated.\n",
      "Expected returns calculated.\n",
      "CAPM TSR metrics calculated.\n",
      "CAPM CSR metrics calculated.\n",
      "CAPM FMP results calculated.\n",
      "CAPM GRS Test Completed.\n",
      "Excess returns calculated.\n",
      "Expected returns calculated.\n",
      "FF3F TSR metrics calculated.\n",
      "FF3F CSR metrics calculated.\n",
      "FF3F FMP results calculated.\n",
      "FF3F GRS Test completed.\n",
      "\n",
      "\n",
      "Results successfully saved to Empirical_Testing_Results.xlsx\n",
      "FF3F results successfully written to Excel sheet.\n"
     ]
    }
   ],
   "source": [
    "capm_csr_results = []\n",
    "capm_fmp_results = []\n",
    "capm_grs_results = []\n",
    "ff3f_csr_results = []\n",
    "ff3f_fmp_results = []\n",
    "ff3f_grs_results = []\n",
    "\n",
    "# get results for each time period\n",
    "for i in range(nper):\n",
    "    print(f'Getting results for time period {i+1}')\n",
    "    # create df for each time period\n",
    "    df_1 = df[(df['Date'] >= start_dates[i]) & (df['Date'] <= end_dates[i])]\n",
    "    \n",
    "    # CAPM\n",
    "    capm = EmpiricalTestsCAPM(df_1)\n",
    "    capm.calculate_excess_returns()\n",
    "    capm.calculate_expected_returns()\n",
    "    capm.calculate_TSR_CAPM()\n",
    "    capm_csr_results.append(capm.calculate_CSR_CAPM())\n",
    "    capm_fmp_results.append(capm.calculate_FMP_CAPM())\n",
    "    capm_grs_results.append(capm.calculate_GRS_CAPM())\n",
    "\n",
    "    # FF3F\n",
    "    ff3f = EmpiricalTestsFF3F(df_1)\n",
    "    ff3f.calculate_excess_returns()\n",
    "    ff3f.calculate_expected_returns()\n",
    "    ff3f.calculate_TSR_FF3F()\n",
    "    ff3f_csr_results.append(ff3f.calculate_CSR_FF3F())\n",
    "    ff3f_fmp_results.append(ff3f.calculate_FMP_FF3F())\n",
    "    ff3f_grs_results.append(ff3f.calculate_GRS_FF3F())\n",
    "    print('\\n')\n",
    "\n",
    "# convert results to dfs for writing\n",
    "capm_csr_results = pd.DataFrame(capm_csr_results, index=periods)\n",
    "capm_csr_results['Significant?'] = capm_csr_results['Lambda_tStat'].abs() >= 1.96\n",
    "capm_fmp_results = pd.DataFrame(capm_fmp_results, index=periods)\n",
    "capm_fmp_results['Significant?'] = capm_fmp_results['Lambda_tStat'].abs() >= 1.96\n",
    "capm_grs_results = pd.DataFrame(capm_grs_results, index=periods)\n",
    "data = {outer_key: pd.DataFrame([result[outer_key] for result in ff3f_csr_results]) \n",
    "        for outer_key in ff3f_csr_results[0]}\n",
    "ff3f_csr_results = pd.concat(data, axis=1)\n",
    "ff3f_csr_results.index = periods\n",
    "data = {outer_key: pd.DataFrame([result[outer_key] for result in ff3f_fmp_results]) \n",
    "        for outer_key in ff3f_fmp_results[0]}\n",
    "ff3f_fmp_results = pd.concat(data, axis=1)\n",
    "ff3f_fmp_results.index = periods\n",
    "ff3f_grs_results = pd.DataFrame(ff3f_grs_results, index=periods)\n",
    "\n",
    "# Write Results\n",
    "wb = Workbook()\n",
    "write_CAPM_to_excel(wb, capm_csr_results, capm_fmp_results, capm_grs_results, filename=\"Empirical_Testing_Results.xlsx\")\n",
    "write_FF3F_to_excel(wb, ff3f_csr_results, ff3f_fmp_results, ff3f_grs_results)\n",
    "# Finally, save the workbook\n",
    "wb.save(\"Empirical_Testing_Results.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
